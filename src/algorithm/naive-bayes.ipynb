{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Algorithm with Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7933333333333333\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data_train = pd.read_csv('../../data/data_train.csv')\n",
    "data_train = data_train[[\"battery_power\", \"mobile_wt\", \"px_height\", \"px_width\", \"ram\", \"price_range\"]]\n",
    "data_validation = pd.read_csv('../../data/data_validation.csv')\n",
    "data_validation = data_validation[[\"battery_power\", \"mobile_wt\", \"px_height\", \"px_width\", \"ram\", \"price_range\"]]\n",
    "def naive_bayes_sklearn(data_train, data_validation): \n",
    "    X_train = data_train.drop(['price_range'], axis=1)\n",
    "    y_train = data_train['price_range']\n",
    "\n",
    "    model = GaussianNB()\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    X_val = data_validation.drop(['price_range'], axis=1)\n",
    "    y_val = data_validation['price_range']\n",
    "\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "\n",
    "    return accuracy \n",
    "\n",
    "accuracy = naive_bayes_sklearn(data_train, data_validation)\n",
    "print('Accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Algorithm Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7333333333333333\n",
      "Hasil:  [2, 2, 3, 0, 3, 1, 3, 0, 3, 1, 2, 2, 3, 0, 3, 0, 2, 1, 0, 2, 2, 1, 0, 1, 1, 1, 2, 2, 0, 2, 1, 3, 3, 1, 2, 3, 1, 3, 1, 1, 0, 2, 0, 2, 2, 1, 1, 3, 1, 3, 1, 2, 3, 0, 1, 3, 2, 3, 3, 1, 1, 3, 3, 0, 3, 2, 2, 2, 2, 2, 2, 3, 1, 0, 1, 2, 0, 2, 1, 0, 3, 3, 0, 2, 3, 0, 3, 3, 0, 3, 1, 1, 0, 2, 1, 0, 3, 2, 1, 2, 3, 2, 1, 2, 3, 2, 3, 2, 3, 3, 3, 3, 2, 2, 3, 1, 0, 3, 1, 3, 0, 2, 2, 3, 2, 1, 2, 2, 1, 3, 3, 1, 0, 0, 3, 0, 0, 1, 3, 0, 1, 3, 3, 1, 2, 2, 1, 2, 1, 2, 3, 1, 0, 2, 1, 0, 3, 0, 0, 3, 3, 3, 0, 2, 3, 0, 0, 0, 0, 2, 3, 1, 0, 1, 1, 1, 3, 0, 2, 0, 3, 1, 1, 2, 0, 2, 0, 3, 1, 0, 3, 2, 0, 1, 2, 0, 1, 3, 3, 1, 1, 2, 2, 3, 2, 3, 3, 3, 0, 3, 0, 2, 3, 1, 2, 3, 2, 0, 0, 2, 2, 1, 3, 3, 0, 2, 0, 3, 0, 2, 1, 2, 2, 1, 3, 0, 1, 3, 3, 3, 0, 0, 1, 1, 3, 3, 1, 2, 0, 2, 1, 2, 3, 3, 0, 2, 1, 1, 1, 2, 0, 2, 2, 3, 3, 0, 1, 3, 3, 0, 1, 2, 1, 1, 1, 0, 3, 3, 2, 2, 0, 1, 0, 1, 1, 1, 1, 0, 3, 0, 3, 0, 1, 0, 1, 3, 2, 2, 0, 2, 1, 0, 1, 1, 1, 2, 0, 3, 1, 1, 0, 2, 3, 1, 3, 1, 3, 1, 2, 2, 0, 0, 2, 0, 2, 1, 0, 1, 1, 0, 3, 2, 3, 2, 2, 2, 3, 0, 1, 0, 1, 1, 0, 2, 2, 2, 2, 3, 1, 2, 3, 0, 2, 1, 2, 3, 2, 3, 2, 0, 3, 0, 0, 2, 2, 0, 3, 2, 1, 2, 1, 0, 1, 2, 1, 3, 0, 0, 2, 1, 0, 2, 1, 0, 3, 3, 3, 3, 0, 0, 0, 3, 1, 0, 3, 0, 0, 2, 0, 3, 1, 0, 1, 1, 1, 2, 0, 1, 1, 3, 3, 1, 2, 2, 3, 1, 1, 2, 2, 2, 0, 1, 3, 0, 0, 1, 0, 0, 0, 3, 1, 1, 2, 0, 1, 2, 1, 0, 3, 3, 1, 0, 2, 0, 2, 1, 1, 0, 2, 0, 0, 2, 0, 2, 0, 3, 0, 0, 1, 2, 1, 1, 3, 2, 1, 2, 3, 0, 3, 2, 0, 2, 2, 2, 0, 0, 3, 0, 2, 0, 1, 3, 0, 0, 3, 0, 2, 2, 3, 3, 1, 3, 3, 0, 1, 2, 1, 3, 1, 0, 3, 1, 3, 3, 1, 2, 3, 0, 3, 2, 1, 2, 0, 3, 0, 3, 2, 0, 2, 3, 0, 3, 0, 2, 3, 3, 0, 2, 1, 2, 3, 3, 3, 1, 1, 0, 2, 2, 3, 2, 2, 3, 1, 1, 0, 0, 3, 0, 2, 1, 1, 3, 2, 1, 1, 3, 1, 3, 0, 0, 3, 3, 3, 1, 2, 2, 0, 2, 0, 1, 0, 2, 0, 1, 0, 0, 2, 3, 0, 1, 1, 1, 0, 1, 2, 0, 1, 3, 0, 2, 1, 0, 0, 1, 2, 1, 3, 0, 1, 3]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "class NaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.data_train = pd.read_csv(\"../../data/data_train.csv\")\n",
    "        #Memilih kolom yang paling berpengaruh pada penilaian\n",
    "        self.data_train = self.data_train[[\"battery_power\", \"mobile_wt\", \"px_height\", \"px_width\", \"ram\", \"price_range\"]]\n",
    "        #Mengubah kolom dari nilai numerik menjadi nilai kategorikal\n",
    "        self.categorical_data_train = self.categorical(self.data_train)\n",
    "\n",
    "    def categorical(self, dataset):\n",
    "        batas = [[864.75, 1219.9, 1655.75], [111.0, 143.0, 172.0], [307.0, 576.5, 928.5], [874.0, 1249.0, 1639.75], [1220.75, 2286.0, 3114.5]]\n",
    "        nama = [\"battery_power\", \"mobile_wt\", \"px_height\", \"px_width\", \"ram\"]\n",
    "        for i in range(len(batas)):\n",
    "            dataset.loc[dataset[nama[i]] <= batas[i][0], nama[i]] = 0\n",
    "            dataset.loc[(dataset[nama[i]] > batas[i][0]) & (dataset[nama[i]] <= batas[i][1]), nama[i]] = 1\n",
    "            dataset.loc[(dataset[nama[i]] > batas[i][1]) & (dataset[nama[i]] <= batas[i][2]), nama[i]] = 2\n",
    "            dataset.loc[dataset[nama[i]] > batas[i][2], nama[i]] = 3\n",
    "        return dataset\n",
    "    \n",
    "    def p_vj(self):\n",
    "        list = []\n",
    "        for i in np.unique(self.data_train[\"price_range\"]):\n",
    "            count = sum(self.data_train[\"price_range\"] == i)\n",
    "            list.append(count/len(self.data_train))\n",
    "        return list\n",
    "\n",
    "    def p_ai_vj(self):\n",
    "        nama = [\"battery_power\", \"mobile_wt\", \"px_height\", \"px_width\", \"ram\"]\n",
    "        list = []\n",
    "        for i in range(len(nama)):\n",
    "            kolom = []\n",
    "            for j in np.unique(self.data_train[\"price_range\"]):\n",
    "                matrix = []\n",
    "                count = sum((self.data_train[\"price_range\"] == j) & (self.data_train[nama[i]] == 0))\n",
    "                matrix.append(count/sum(self.data_train[\"price_range\"] == j))\n",
    "                count = sum((self.data_train[\"price_range\"] == j) & (self.data_train[nama[i]] == 1))\n",
    "                matrix.append(count/sum(self.data_train[\"price_range\"] == j))\n",
    "                count = sum((self.data_train[\"price_range\"] == j) & (self.data_train[nama[i]] == 2))\n",
    "                matrix.append(count/sum(self.data_train[\"price_range\"] == j))\n",
    "                count = sum((self.data_train[\"price_range\"] == j) & (self.data_train[nama[i]] == 3))\n",
    "                matrix.append(count/sum(self.data_train[\"price_range\"] == j))\n",
    "                kolom.append(matrix)\n",
    "            list.append(kolom)    \n",
    "        return list\n",
    "    \n",
    "    def posterior(self, data_validation):\n",
    "        prior = self.p_vj()\n",
    "        likelihood = self.p_ai_vj()\n",
    "        data_validation = self.categorical(data_validation)\n",
    "        nama = [\"battery_power\", \"mobile_wt\", \"px_height\", \"px_width\", \"ram\"]\n",
    "        list = []\n",
    "        for i in range(len(data_validation)):\n",
    "            matrix = []\n",
    "            for j in range(len(prior)):\n",
    "                matrix.append(prior[j])\n",
    "                for k in range(len(nama)):\n",
    "                    matrix[j] = matrix[j] * likelihood[k][j][data_validation[nama[k]][i]]\n",
    "\n",
    "            list.append(matrix)\n",
    "        return list\n",
    "    \n",
    "    def predict(self, data_validation):\n",
    "        Posterior = self.posterior(data_validation)\n",
    "\n",
    "        list = []\n",
    "        for i in range(len(Posterior)):\n",
    "            list.append(np.argmax(Posterior[i]))\n",
    "        count = 0\n",
    "        for i in range(len(data_validation)):\n",
    "            if list[i] == data_validation[\"price_range\"][i]:\n",
    "                count += 1\n",
    "        return list, count/len(data_validation)\n",
    "    \n",
    "    def get_result(self, data_val, index):\n",
    "        posterior = self.posterior(data_val)\n",
    "        list = []\n",
    "        for i in range(len(posterior)):\n",
    "            list.append(np.argmax(posterior[i]))\n",
    "\n",
    "        return list[index]\n",
    "    \n",
    "    def save_model(self, filename):\n",
    "        pickle.dump(self, open(\"../model/\"+ filename, 'wb'))\n",
    "\n",
    "categorical_data_validation = pd.read_csv(\"../../data/data_validation.csv\")\n",
    "model = NaiveBayes()\n",
    "hasil, persentase = model.predict(categorical_data_validation)\n",
    "getResult = model.get_result(categorical_data_validation, 2)\n",
    "model.save_model(\"NB_model.pkl\")\n",
    "print('Accuracy: ', persentase)\n",
    "print('Hasil: ', hasil)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7333333333333333\n",
      "Hasil:  [2, 2, 3, 0, 3, 1, 3, 0, 3, 1, 2, 2, 3, 0, 3, 0, 2, 1, 0, 2, 2, 1, 0, 1, 1, 1, 2, 2, 0, 2, 1, 3, 3, 1, 2, 3, 1, 3, 1, 1, 0, 2, 0, 2, 2, 1, 1, 3, 1, 3, 1, 2, 3, 0, 1, 3, 2, 3, 3, 1, 1, 3, 3, 0, 3, 2, 2, 2, 2, 2, 2, 3, 1, 0, 1, 2, 0, 2, 1, 0, 3, 3, 0, 2, 3, 0, 3, 3, 0, 3, 1, 1, 0, 2, 1, 0, 3, 2, 1, 2, 3, 2, 1, 2, 3, 2, 3, 2, 3, 3, 3, 3, 2, 2, 3, 1, 0, 3, 1, 3, 0, 2, 2, 3, 2, 1, 2, 2, 1, 3, 3, 1, 0, 0, 3, 0, 0, 1, 3, 0, 1, 3, 3, 1, 2, 2, 1, 2, 1, 2, 3, 1, 0, 2, 1, 0, 3, 0, 0, 3, 3, 3, 0, 2, 3, 0, 0, 0, 0, 2, 3, 1, 0, 1, 1, 1, 3, 0, 2, 0, 3, 1, 1, 2, 0, 2, 0, 3, 1, 0, 3, 2, 0, 1, 2, 0, 1, 3, 3, 1, 1, 2, 2, 3, 2, 3, 3, 3, 0, 3, 0, 2, 3, 1, 2, 3, 2, 0, 0, 2, 2, 1, 3, 3, 0, 2, 0, 3, 0, 2, 1, 2, 2, 1, 3, 0, 1, 3, 3, 3, 0, 0, 1, 1, 3, 3, 1, 2, 0, 2, 1, 2, 3, 3, 0, 2, 1, 1, 1, 2, 0, 2, 2, 3, 3, 0, 1, 3, 3, 0, 1, 2, 1, 1, 1, 0, 3, 3, 2, 2, 0, 1, 0, 1, 1, 1, 1, 0, 3, 0, 3, 0, 1, 0, 1, 3, 2, 2, 0, 2, 1, 0, 1, 1, 1, 2, 0, 3, 1, 1, 0, 2, 3, 1, 3, 1, 3, 1, 2, 2, 0, 0, 2, 0, 2, 1, 0, 1, 1, 0, 3, 2, 3, 2, 2, 2, 3, 0, 1, 0, 1, 1, 0, 2, 2, 2, 2, 3, 1, 2, 3, 0, 2, 1, 2, 3, 2, 3, 2, 0, 3, 0, 0, 2, 2, 0, 3, 2, 1, 2, 1, 0, 1, 2, 1, 3, 0, 0, 2, 1, 0, 2, 1, 0, 3, 3, 3, 3, 0, 0, 0, 3, 1, 0, 3, 0, 0, 2, 0, 3, 1, 0, 1, 1, 1, 2, 0, 1, 1, 3, 3, 1, 2, 2, 3, 1, 1, 2, 2, 2, 0, 1, 3, 0, 0, 1, 0, 0, 0, 3, 1, 1, 2, 0, 1, 2, 1, 0, 3, 3, 1, 0, 2, 0, 2, 1, 1, 0, 2, 0, 0, 2, 0, 2, 0, 3, 0, 0, 1, 2, 1, 1, 3, 2, 1, 2, 3, 0, 3, 2, 0, 2, 2, 2, 0, 0, 3, 0, 2, 0, 1, 3, 0, 0, 3, 0, 2, 2, 3, 3, 1, 3, 3, 0, 1, 2, 1, 3, 1, 0, 3, 1, 3, 3, 1, 2, 3, 0, 3, 2, 1, 2, 0, 3, 0, 3, 2, 0, 2, 3, 0, 3, 0, 2, 3, 3, 0, 2, 1, 2, 3, 3, 3, 1, 1, 0, 2, 2, 3, 2, 2, 3, 1, 1, 0, 0, 3, 0, 2, 1, 1, 3, 2, 1, 1, 3, 1, 3, 0, 0, 3, 3, 3, 1, 2, 2, 0, 2, 0, 1, 0, 2, 0, 1, 0, 0, 2, 3, 0, 1, 1, 1, 0, 1, 2, 0, 1, 3, 0, 2, 1, 0, 0, 1, 2, 1, 3, 0, 1, 3]\n"
     ]
    }
   ],
   "source": [
    "loaded_model = pickle.load(open(\"../model/NB_model.pkl\", 'rb'))\n",
    "data_validation = pd.read_csv(\"../../data/data_validation.csv\")\n",
    "hasil, persentase = loaded_model.predict(data_validation)\n",
    "getAccuracy = loaded_model.get_result(data_validation, 2)\n",
    "print('Accuracy: ', persentase)\n",
    "print('Hasil: ', hasil)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
